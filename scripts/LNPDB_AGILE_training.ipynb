{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1de80bb9-077f-43a3-9f7b-ed41042f8583",
   "metadata": {},
   "source": [
    "# 1. Installation of requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20d12f28-0a1b-4a4b-a1a4-a4dae12b06e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# required packages and basic function(s)\n",
    "from rdkit import Chem\n",
    "from mordred import Calculator, descriptors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import tqdm\n",
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from importlib import resources\n",
    "import subprocess\n",
    "import logging\n",
    "from multiprocessing import freeze_support\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "freeze_support()\n",
    "\n",
    "def safe_div(value, factor, feature_name, printed_flag):\n",
    "    try:\n",
    "        return value / np.float64(factor)\n",
    "    except Exception:\n",
    "        # only print the first time this feature fails\n",
    "        if not printed_flag[0]:\n",
    "            print(f\"{feature_name} unable to be calculated, setting invalid values to 0\")\n",
    "            printed_flag[0] = True\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2980fbfb-8c3a-45ce-b9b6-4706b806c3f5",
   "metadata": {},
   "source": [
    "# 2. Splitting data into test/train splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11d3bbf-7e20-4a8f-8e88-39d4fcceac5e",
   "metadata": {},
   "source": [
    "\n",
    "The pre-trained AGILE deep learning model is provided in `AGILE/ckpt/pretrained_agile_60k` and will be fine-tuned on five cross-validation splits.\n",
    "\n",
    "The data provided in [repo](https://github.com/bowang-lab/AGILE) was split (80% train/20% validation) randomly to create these splits.\n",
    "\n",
    "In this section we will split the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9985e14-19db-45b4-8bd9-d51f5a476c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Cross-validation splits saved to cv_splits/\n"
     ]
    }
   ],
   "source": [
    "# split AGILE data (Morgan fingerprints included)\n",
    "random.seed(0)\n",
    "no_splits = 5\n",
    "\n",
    "# read from ../LNPDB/data/LNPDB_for_AGILE/data\n",
    "df = pd.read_csv(\"../data/LNPDB_for_AGILE/AGILE/data/data/finetuning_set_smiles_plus_features.csv\")\n",
    "\n",
    "def create_df(name):\n",
    "    name = pd.DataFrame()\n",
    "    return name\n",
    "\n",
    "output_dataframes=[]\n",
    "for i in range(no_splits):\n",
    "    output_dataframes.append(create_df(f\"df{i}\"))\n",
    "\n",
    "complement_dataframes=[]\n",
    "for k in range(no_splits):\n",
    "    complement_dataframes.append(create_df(f\"df{k}c\"))\n",
    "\n",
    "for index in range(len(df)):\n",
    "    row = df.iloc[[index]]\n",
    "    assignment = random.randint(0,no_splits-1)\n",
    "    while len(output_dataframes[assignment])>=len(df)/no_splits:\n",
    "        assignment = random.randint(0,no_splits-1)\n",
    "    output_dataframes[assignment] = pd.concat([output_dataframes[assignment], row], ignore_index=True)\n",
    "    for complement_assignment in range(no_splits):\n",
    "        if complement_assignment != assignment:\n",
    "            complement_dataframes[complement_assignment] = pd.concat([complement_dataframes[complement_assignment], row], ignore_index=True)\n",
    "\n",
    "# save to ../LNPDB/data/LNPDB_for_AGILE/cv_splits\n",
    "cv_dir = Path(\"../data/LNPDB_for_AGILE/cv_splits\")\n",
    "cv_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for j, dataframe in enumerate(output_dataframes):\n",
    "    dataframe.to_csv(cv_dir / f\"df{j}_test.csv\", index=False)\n",
    "\n",
    "for k, dataframe in enumerate(complement_dataframes):\n",
    "    dataframe.to_csv(cv_dir / f\"df{k}_train.csv\", index=False)\n",
    "\n",
    "logging.info(\"Cross-validation splits saved to cv_splits/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18502eb8-024e-4c66-96cc-72583efc024d",
   "metadata": {},
   "source": [
    "# 3. Finetuning models on cross-validation splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d19d62f-2e87-4914-b946-4855b13f3621",
   "metadata": {},
   "source": [
    "The following section involves preparing files according to [AGILE](https://github.com/bowang-lab/AGILE).\n",
    "    \n",
    "Note that finetuning is nondeterministic especially with AGILE code being unseeded, and results may differ slightly between finetuned models.\n",
    "\n",
    "The models and their results are now placed in respective folders in `LNPDB/data/LNPDB_for_AGILE/AGILE/finetune`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b85df9-8360-4d7c-874d-12e80ebdc8f9",
   "metadata": {},
   "source": [
    "## 3.1 Preparing finetune_LNPDB.py and YAML/split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d438e9bb-3153-4680-80bd-c8a19f50f31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:finetune_LNPDB.py and split YAMLs prepared in AGILE/\n"
     ]
    }
   ],
   "source": [
    "lnpdb_agile_base = Path(\"../data/LNPDB_for_AGILE\")\n",
    "scripts_dir = Path(\"../data/LNPDB_for_AGILE/scripts\")\n",
    "agile_dir = Path(\"../data/LNPDB_for_AGILE/AGILE\")\n",
    "\n",
    "# Copy finetune script + yaml into AGILE, and patch YAML per split\n",
    "finetune_py = scripts_dir / \"finetune_LNPDB.py\"\n",
    "finetune_yaml_template = scripts_dir / \"config_finetune.yaml\"\n",
    "\n",
    "# Ensure files exist\n",
    "assert finetune_py.exists(), \"finetune_LNPDB.py not found in scripts/\"\n",
    "assert finetune_yaml_template.exists(), \"config_finetune.yaml not found in scripts/\"\n",
    "\n",
    "# Copy finetune_LNPDB.py into AGILE\n",
    "shutil.copy(finetune_py, agile_dir / \"finetune_LNPDB.py\")\n",
    "\n",
    "# Generate one YAML per split\n",
    "finetune_config_dir = agile_dir / \"finetune\"\n",
    "finetune_config_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for i in range(5):\n",
    "    yaml_target = finetune_config_dir / f\"agile_lnp_hela_cv_{i}.yaml\"\n",
    "    with open(finetune_yaml_template, \"r\") as f:\n",
    "        yaml_text = f.read()\n",
    "    yaml_text = yaml_text.replace(\n",
    "        \"task_name: lnp_hela_with_feat\",\n",
    "        f\"task_name: LNPDB_split_{i}\"\n",
    "    )\n",
    "    with open(yaml_target, \"w\") as f:\n",
    "        f.write(yaml_text)\n",
    "\n",
    "logging.info(\"finetune_LNPDB.py and split YAMLs prepared in AGILE/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61fbbd5-9053-4eaa-b0ab-c898a6504772",
   "metadata": {},
   "source": [
    "## 3.2 Finetuning models on respective split train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c72f38d6-a24b-4534-bbda-6bfb35b4ebb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Finetuned models in AGILE/finetune named agile_lnp_hela_cv_{i}/\n"
     ]
    }
   ],
   "source": [
    "# finetune pre-trained AGILE model on 5 cross-validation splits\n",
    "cv_number_list = [0,1,2,3,4]\n",
    "\n",
    "finetune_dir = Path(\"finetune\")\n",
    "scripts_dir = Path(\"../scripts\")\n",
    "for i in cv_number_list:\n",
    "    yaml_path = finetune_dir / f\"agile_lnp_hela_cv_{i}.yaml\"\n",
    "    command = [\"python\", \"finetune_LNPDB.py\", str(yaml_path)]\n",
    "    result = subprocess.run(command, cwd=agile_dir, capture_output=True, text=True)\n",
    "    # uncomment to show the direct AGILE output and errors\n",
    "    # print(result.stdout)\n",
    "    # print(result.stderr)\n",
    "    \n",
    "logging.info(\"Finetuned models in AGILE/finetune named agile_lnp_hela_cv_{i}/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba06bb0-c3b2-4622-8931-7ad445647ec1",
   "metadata": {},
   "source": [
    "# 4. Generating LNPDB data feature descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2173d8fc-fa2a-4936-aad0-676c2b4f2755",
   "metadata": {},
   "source": [
    "To use the trained models to predict delivery efficacy for new LNP data, LNPDB data has been placed into the folder `LNPDB/data/LNPDB_for_AGILE/LNPDB_data`.\n",
    "\n",
    "AGILE requires data to be processed into Mordred molecular feature descriptors, which are generated using [repo](https://github.com/mordred-descriptor/mordred) as described in the sixth cell of the notebook. Note that the \"descriptors_full\" output is from directly generating Mordred descriptors, while the \"plus_features\" output is with adjustment to required AGILE format. For all LNPDB data included in the paper, this repository already contains the corresponding Mordred descriptors in `LNPDB/data/LNPDB_for_AGILE/LNPDB_data`.\n",
    "\n",
    "Our Mordred descriptors were validated by comparing generation from AGILE original SMILES and provided fingerprints. The procedure is to generate Mordred descriptors using solely the smiles and Experiment_value columns, and then compare the resulting descriptors with those provided by the AGILE [repo](https://github.com/bowang-lab/AGILE)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7585d586-48ef-4e89-a1fa-d3e94cd21bdd",
   "metadata": {},
   "source": [
    "## 4.1 Generate descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d5d0088-3f07-4964-88cd-c065b9b6e857",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Read heldout data with 1200 molecules.\n",
      "/home/andersonxps/anaconda3/envs/agile_finaltest_lnpdb/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1200/1200 [03:28<00:00,  5.75it/s]\n",
      "INFO:root:Full descriptor table saved to ../data/LNPDB_for_AGILE/outputs/finetuning_set_smiles_plus_features_descriptors_full.csv.\n",
      "INFO:root:Found 813 desired desc_* columns in known data.\n",
      "INFO:root:Augmented heldout data (with 813 descriptors) saved to ../data/LNPDB_for_AGILE/outputs/finetuning_set_smiles_plus_features_plus_features.csv\n"
     ]
    }
   ],
   "source": [
    "# Generate Mordred descriptors for heldout datasets and align with known features\n",
    "def heldout_data(heldout_data_path: str,\n",
    "                 heldout_data_output_folder: str,\n",
    "                 known_data_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Generate Mordred descriptors for molecules in heldout_data, then select only\n",
    "    those features that appear in known_data and append them to the heldout_data.\n",
    "    Saves both the full descriptor table and the filtered heldout_data to CSV files.\n",
    "\n",
    "    Parameters:\n",
    "    - heldout_data_path: path to CSV with columns ['smiles', ...]\n",
    "    - heldout_data_output_folder: folder to create for output files\n",
    "    - known_data_path: path to CSV whose columns define the desired features\n",
    "    \"\"\"\n",
    "\n",
    "    df_heldout = pd.read_csv(heldout_data_path)\n",
    "    logging.info(f\"Read heldout data with {len(df_heldout)} molecules.\")\n",
    "    try:\n",
    "        mols = [Chem.MolFromSmiles(smi) for smi in df_heldout['smiles']]\n",
    "    except:\n",
    "        mols = [Chem.MolFromSmiles(smi) for smi in df_heldout['IL_SMILES']]\n",
    "    calc = Calculator(descriptors, ignore_3D=True)\n",
    "    df_desc = calc.pandas(mols, nproc=1)\n",
    "\n",
    "    # clean columns\n",
    "    if isinstance(df_desc.columns, pd.MultiIndex):\n",
    "        df_desc.columns = [str(name) for name, _ in df_desc.columns]\n",
    "    else:\n",
    "        df_desc.columns = [str(c) for c in df_desc.columns]\n",
    "\n",
    "    df_desc.replace([np.inf, -np.inf], pd.NA, inplace=True)\n",
    "\n",
    "    if df_desc.isna().sum().sum() > 0:\n",
    "        logging.warning(f\"Detected {df_desc.isna().sum().sum()} NaN or overflow values after descriptor calculation.\")\n",
    "\n",
    "    os.makedirs(heldout_data_output_folder, exist_ok=True)\n",
    "    dataset_name = Path(heldout_data_path).stem\n",
    "\n",
    "    desc_full_path = os.path.join(heldout_data_output_folder,\n",
    "                                  f\"{dataset_name}_descriptors_full.csv\")\n",
    "    df_desc.to_csv(desc_full_path, index=False)\n",
    "    logging.info(f\"Full descriptor table saved to {desc_full_path}.\")\n",
    "\n",
    "    df_known = pd.read_csv(known_data_path)\n",
    "    desired_cols = [col for col in df_known.columns if col.startswith('desc_')]\n",
    "    logging.info(f\"Found {len(desired_cols)} desired desc_* columns in known data.\")\n",
    "\n",
    "    # collect matching columns\n",
    "    new_features = {}\n",
    "    missing_features = []\n",
    "    overflow_features = []\n",
    "    # Extract feature names from desired columns\n",
    "    scaling_factor = None\n",
    "    for col in desired_cols:\n",
    "        # some features used by AGILE are scaled\n",
    "        if '/' in col:\n",
    "            feature_name, scaling_factor = col[len('desc_'):].split('/')\n",
    "        else:\n",
    "            feature_name = col[len('desc_'):] \n",
    "\n",
    "        if feature_name in df_desc.columns:\n",
    "            feature_values = df_desc[feature_name]\n",
    "            printed_flag = [False]\n",
    "            if feature_values.isna().any():\n",
    "                logging.warning(f\"Feature '{feature_name}' contains NaNs due to overflow during calculation.\")\n",
    "                overflow_features.append(feature_name)\n",
    "            # else if feature_name == 'MAXssNH' or feature_name == 'MINssNH':\n",
    "            elif scaling_factor:\n",
    "                new_features[col] = [\n",
    "                    safe_div(value, scaling_factor, feature_name, printed_flag)\n",
    "                    for value in feature_values.values\n",
    "                ]\n",
    "            else:\n",
    "                new_features[col] = [\n",
    "                    safe_div(value, 1, feature_name, printed_flag)\n",
    "                    for value in feature_values.values\n",
    "                ]\n",
    "            # uncomment to see all features during generation\n",
    "            # logging.info(f\"Added feature column '{col}' from descriptor '{feature_name}'.\")\n",
    "        else:\n",
    "            # some features used by AGILE are log-Mordred features\n",
    "            if feature_name == 'log_VR1_A' or feature_name == 'log_VR2_A' or feature_name == 'log_SdssC':\n",
    "                feature_values = df_desc[f'{feature_name[4:]}']\n",
    "                if feature_values.isna().any():\n",
    "                    logging.warning(f\"Feature '{feature_name}' contains NaNs due to overflow during calculation.\")\n",
    "                    overflow_features.append(f'log_{feature_name}')\n",
    "                new_features[col] = [math.log10(value) if value>0 else 0 for value in feature_values.values]\n",
    "                # uncomment to see all features during generation\n",
    "                # logging.info(f\"Added feature column '{col}' from descriptor '{feature_name}'.\")\n",
    "            else:\n",
    "                logging.warning(f\"Descriptor '{feature_name}' not found in calculated descriptors. Filling NaNs.\")\n",
    "                new_features[col] = [pd.NA] * len(df_heldout)\n",
    "                missing_features.append(feature_name)\n",
    "\n",
    "        scaling_factor = None\n",
    "\n",
    "    df_new_features = pd.DataFrame(new_features)\n",
    "    df_new_features = df_new_features.reindex(columns=desired_cols)\n",
    "    df_heldout = pd.concat([df_heldout.reset_index(drop=True),\n",
    "                            df_new_features.reset_index(drop=True)], axis=1)\n",
    "    # df_heldout.rename(columns={'IL_SMILES': 'smiles'}, inplace=True)\n",
    "\n",
    "    # ðŸ”¹ Ensure only known features are kept (drop extra Mordred descriptors)\n",
    "    keep_cols = [c for c in df_heldout.columns if not c.startswith(\"desc_\")] + desired_cols\n",
    "    df_heldout = df_heldout[keep_cols]\n",
    "\n",
    "    # concatenate smiles + labels (non-desc_) with filtered descriptors\n",
    "    non_desc_cols = [c for c in df_heldout.columns if not c.startswith(\"desc_\")]\n",
    "    df_heldout_final = pd.concat(\n",
    "        [df_heldout[non_desc_cols].reset_index(drop=True),\n",
    "         df_new_features.reset_index(drop=True)],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Ensure final output columns match the order in known_data\n",
    "    ref_cols = list(df_known.columns)  # full reference column order\n",
    "    non_desc_cols = [c for c in df_heldout_final.columns if not c.startswith(\"desc_\")]\n",
    "\n",
    "    # keep non-desc columns first, then descriptors in reference order\n",
    "    ordered_cols = non_desc_cols + [c for c in ref_cols if c.startswith(\"desc_\")]\n",
    "\n",
    "    df_heldout_final = df_heldout_final.reindex(columns=ordered_cols)\n",
    "    if 'IL_SMILES' in df_heldout_final.columns:\n",
    "        df_heldout_final = df_heldout_final.rename(columns={'IL_SMILES': 'smiles'})\n",
    "    \n",
    "    heldout_out_path = os.path.join(heldout_data_output_folder, f\"{dataset_name}_plus_features.csv\")\n",
    "\n",
    "    df_heldout_final.to_csv(heldout_out_path, index=False)\n",
    "\n",
    "    logging.info(f\"Augmented heldout data (with {len(desired_cols)} descriptors) saved to {heldout_out_path}\")\n",
    "\n",
    "    # Warn about missing features if any\n",
    "    if missing_features:\n",
    "        logging.warning(f\"{len(missing_features)} features were missing: {missing_features}\")\n",
    "\n",
    "    if overflow_features:\n",
    "        logging.warning(f\"{len(overflow_features)} features contain NaN values due to overflow: {overflow_features}\")\n",
    "\n",
    "# Example call (edit datasets as needed)\n",
    "heldout_data(\n",
    "    \"../data/LNPDB_for_AGILE/AGILE/data/data/finetuning_set_smiles_plus_features.csv\", # only change this argument for each dataset\n",
    "    #\"../data/LNPDB_for_AGILE/LNPDB_data/BL_2023_heldout_data.csv\",\n",
    "    #\"../data/LNPDB_for_AGILE/LNPDB_data/LM_2019_heldout_data.csv\",\n",
    "    #\"../data/LNPDB_for_AGILE/LNPDB_data/SL_2020_heldout_data.csv\",\n",
    "    #\"../data/LNPDB_for_AGILE/LNPDB_data/ZC_2023_heldout_data.csv\",\n",
    "    \"../data/LNPDB_for_AGILE/outputs\",\n",
    "    \"../data/LNPDB_for_AGILE/AGILE/data/data/finetuning_set_smiles_plus_features.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ac3450-5bff-42e7-b3dc-e3ce7401f48a",
   "metadata": {},
   "source": [
    "## 4.2 Validate descriptor generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "266646aa-83d9-4381-9907-a8ebffeb5fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total known features: 813\n",
      "Total generated features: 813\n",
      "Overlap: 813\n",
      "\n",
      "Summary:\n",
      "- Total values compared: 975600\n",
      "- Mismatched values: 0\n",
      "- % values matching: 100.00%\n",
      "- % molecules with all descriptors matching: 100.00%\n",
      "Column order identical: True\n"
     ]
    }
   ],
   "source": [
    "# Compare generated Mordred descriptors vs. known features, with summary stats\n",
    "def compare_descriptors(generated_path: str, known_path: str, n_check: int = 5,\n",
    "                        atol: float = 1e-6, rtol: float = 1e-4):\n",
    "    \"\"\"\n",
    "    Compare a generated Mordred descriptor CSV to a known training feature CSV.\n",
    "\n",
    "    Parameters:\n",
    "    - generated_path: path to heldout_data_output.csv (with descriptors)\n",
    "    - known_path: path to finetuning_set_smiles_plus_features.csv\n",
    "    - n_check: number of molecules to sample for detailed row comparison\n",
    "    - atol, rtol: tolerances for numerical equality (absolute, relative)\n",
    "    \"\"\"\n",
    "    df_gen = pd.read_csv(generated_path)\n",
    "    df_known = pd.read_csv(known_path)\n",
    "\n",
    "    # Select only descriptor columns (start with desc_)\n",
    "    gen_cols = [c for c in df_gen.columns if c.startswith(\"desc_\")]\n",
    "    known_cols = [c for c in df_known.columns if c.startswith(\"desc_\")]\n",
    "\n",
    "    # Check overlap\n",
    "    overlap = sorted(set(gen_cols) & set(known_cols))\n",
    "    missing_in_gen = set(known_cols) - set(gen_cols)\n",
    "    extra_in_gen = set(gen_cols) - set(known_cols)\n",
    "\n",
    "    print(f\"Total known features: {len(known_cols)}\")\n",
    "    print(f\"Total generated features: {len(gen_cols)}\")\n",
    "    print(f\"Overlap: {len(overlap)}\")\n",
    "    if missing_in_gen:\n",
    "        print(f\"Missing in generated: {sorted(list(missing_in_gen))[:10]} ...\")\n",
    "    if extra_in_gen:\n",
    "        print(f\"Extra in generated: {sorted(list(extra_in_gen))[:10]} ...\")\n",
    "\n",
    "    # Early exit if no overlap\n",
    "    if not overlap:\n",
    "        print(\"No overlapping descriptors to compare.\")\n",
    "        return\n",
    "\n",
    "    # Align dataframes to overlap\n",
    "    df_gen_overlap = df_gen[overlap].reset_index(drop=True)\n",
    "    df_known_overlap = df_known[overlap].reset_index(drop=True)\n",
    "\n",
    "    # Check shape match\n",
    "    n_rows = min(len(df_gen_overlap), len(df_known_overlap))\n",
    "    df_gen_overlap = df_gen_overlap.iloc[:n_rows]\n",
    "    df_known_overlap = df_known_overlap.iloc[:n_rows]\n",
    "\n",
    "    # Compare all values\n",
    "    diffs_mask = ~np.isclose(df_gen_overlap.values,\n",
    "                             df_known_overlap.values,\n",
    "                             atol=atol, rtol=rtol, equal_nan=True)\n",
    "\n",
    "    n_total = diffs_mask.size\n",
    "    n_diffs = np.count_nonzero(diffs_mask)\n",
    "    pct_match = 100 * (1 - n_diffs / n_total)\n",
    "\n",
    "    # Molecule-level agreement\n",
    "    row_match = np.all(~diffs_mask, axis=1)\n",
    "    pct_rows_match = 100 * np.mean(row_match)\n",
    "\n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"- Total values compared: {n_total}\")\n",
    "    print(f\"- Mismatched values: {n_diffs}\")\n",
    "    print(f\"- % values matching: {pct_match:.2f}%\")\n",
    "    print(f\"- % molecules with all descriptors matching: {pct_rows_match:.2f}%\")\n",
    "\n",
    "    # Column order check (binary)\n",
    "    same_order = gen_cols == known_cols\n",
    "    print(f\"Column order identical: {same_order}\")\n",
    "            \n",
    "# verify mordred generation algorithm on original AGILE data\n",
    "compare_descriptors(\n",
    "    \"../data/LNPDB_for_AGILE/outputs/finetuning_set_smiles_plus_features_plus_features.csv\", # features generated by code on AGILE smiles\n",
    "    \"../data/LNPDB_for_AGILE/AGILE/data/data/finetuning_set_smiles_plus_features.csv\" # features provided with AGILE data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20034ca3-5f32-4ae4-9c79-056317fd8036",
   "metadata": {},
   "source": [
    "# 5. Evaluating models on AGILE and LNPDB data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665811e7-95ef-4cc5-93db-097bece74fc6",
   "metadata": {},
   "source": [
    "Once the molecular feature descriptors are generated, AGILE splits can make predictions on delivery efficacy for LNPDB data.\n",
    "\n",
    "The following blocks move`infer_vis_LNPDB.py` into AGILE from `LNPDB/data/LNPDB_for_AGILE/scripts`, evaluate the fine-tuned AGILE models on the test cross-evaluation splits and make predictions on data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be968627-2764-4a2d-8788-dddb7139dd1b",
   "metadata": {},
   "source": [
    "## 5.1 Preparing infer_vis_LNPDB.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a42da57a-10af-4094-b889-ed7ce4ac16ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:infer_vis_LNPDB.py copied.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/LNPDB_for_AGILE/scripts/infer_vis_LNPDB.py\n"
     ]
    }
   ],
   "source": [
    "# Copy infer_vis_LNPDB.py and infer yaml into AGILE model folders\n",
    "scripts_dir = Path(\"../data/LNPDB_for_AGILE/scripts\")\n",
    "infer_py = scripts_dir / \"infer_vis_LNPDB.py\"\n",
    "infer_yaml_template = scripts_dir / \"infer_vis/config_finetune.yaml\"\n",
    "print(infer_py)\n",
    "\n",
    "# Ensure files exist\n",
    "assert infer_py.exists(), \"infer_vis_LNPDB.py not found in scripts/\"\n",
    "assert infer_yaml_template.exists(), \"infer_vis/config_finetune.yaml not found in scripts/\"\n",
    "\n",
    "# Copy infer_vis_LNPDB.py into AGILE\n",
    "shutil.copy(infer_py, agile_dir / \"infer_vis_LNPDB.py\")\n",
    "\n",
    "logging.info(\"infer_vis_LNPDB.py copied.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2666e82-b121-4794-9ad0-bc88a5647c58",
   "metadata": {},
   "source": [
    "## 5.2 Evaluate fine-tuned models on test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b926e6b-c185-4ab4-bb92-2e4753d6c697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Averaged results across CV splits ===\n",
      "Average loss = 10.1025, Average RMSE = 3.1737, Pearson Corr = 0.3261\n"
     ]
    }
   ],
   "source": [
    "# do cross-validation on the test splits\n",
    "def test_split_validation() -> None:\n",
    "    \"\"\"\n",
    "    Run the AGILE cross-evaluation splits on respective test splits\n",
    "    \"\"\"\n",
    "    result_loss = []\n",
    "    result_rmse = []\n",
    "    result_corr = []\n",
    "    cv_number_list = [0, 1, 2, 3, 4]\n",
    "    # run infer_vis\n",
    "    for cv_number in cv_number_list:\n",
    "        model_path = Path(f\"agile_lnp_hela_cv_{cv_number}\")\n",
    "        yaml_path = f\"../data/LNPDB_for_AGILE/AGILE/finetune/agile_lnp_hela_cv_{cv_number}/checkpoints/config_finetune.yaml\"\n",
    "        # replace yaml value based on dataset_name\n",
    "        with open(yaml_path, \"r\") as f:\n",
    "                yaml_config = yaml.safe_load(f)\n",
    "        # Modify the parameter\n",
    "        yaml_config['task_name'] = f\"df{cv_number}_test\"\n",
    "        # Write the updated data back to the file\n",
    "        with open(yaml_path, 'w') as file:\n",
    "            yaml.safe_dump(yaml_config, file, default_flow_style=False, sort_keys=False)\n",
    "        command = [\"python\", \"infer_vis_LNPDB.py\", str(model_path)]\n",
    "        result = subprocess.run(command, cwd=agile_dir, capture_output=True, text=True)\n",
    "        try:\n",
    "            import re\n",
    "            stdout_vals = [float(x) for x in re.findall(r\"[+-]?(?:\\d+\\.\\d*|\\.\\d+|\\d+)(?:[eE][+-]?\\d+)?\", result.stdout)]\n",
    "\n",
    "        except ValueError:\n",
    "            print(f\"Warning: could not convert stdout/stderr to float for {dataset_name} CV {cv_number}\")\n",
    "            continue\n",
    "\n",
    "        # uncomment to show the direct AGILE output and errors\n",
    "        # print(result.stdout)\n",
    "        # print(result.stderr)\n",
    "\n",
    "        result_loss.append(stdout_vals[-17])\n",
    "        result_rmse.append(stdout_vals[-16])\n",
    "        result_corr.append(stdout_vals[-15])\n",
    "\n",
    "    print(\"\\n=== Averaged results across CV splits ===\")\n",
    "    loss_avg = sum(result_loss) / len(result_loss) if result_loss else float(\"nan\")\n",
    "    rmse_avg = sum(result_rmse) / len(result_rmse) if result_rmse else float(\"nan\")\n",
    "    corr_avg = sum(result_corr) / len(result_corr) if result_corr else float(\"nan\")\n",
    "    print(f\"Average loss = {loss_avg:.4f}, Average RMSE = {rmse_avg:.4f}, Pearson Corr = {corr_avg:.4f}\")\n",
    "\n",
    "test_split_validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a3fe74-01c8-4453-b96f-cfc3282f8151",
   "metadata": {},
   "source": [
    "## 5.3 Make predictions on LNPDB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df42ce43-1f57-4719-9de6-954c92fc6e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Averaged results across CV splits ===\n",
      "BL_2023_heldout_data: Average loss = 32.5733, Average RMSE = 5.6852, Pearson Corr = -0.0215\n",
      "LM_2019_heldout_data: Average loss = 47.7940, Average RMSE = 6.9071, Pearson Corr = -0.0158\n",
      "SL_2020_heldout_data: Average loss = 47.9252, Average RMSE = 6.8049, Pearson Corr = -0.2242\n",
      "ZC_2023_heldout_data: Average loss = 47.1363, Average RMSE = 6.7901, Pearson Corr = 0.2167\n"
     ]
    }
   ],
   "source": [
    "# evaluate cross-validation splits on dataset\n",
    "def cross_evaluate() -> None:\n",
    "    \"\"\"\n",
    "    Run the AGILE cross-evaluation splits on LNPDB data\n",
    "    \"\"\"\n",
    "    cv_number_list = [0, 1, 2, 3, 4]\n",
    "    # datasets to evaluate\n",
    "    datasets = [\"BL_2023_heldout_data\", \"LM_2019_heldout_data\", \"SL_2020_heldout_data\", \"ZC_2023_heldout_data\"]\n",
    "    dataset_metrics = {dataset_name: {\"loss\": [], \"rmse\": [], \"corr\": []} for dataset_name in datasets}\n",
    "    for dataset_name in datasets:\n",
    "        # run infer_vis\n",
    "        for cv_number in cv_number_list:\n",
    "            model_path = Path(f\"agile_lnp_hela_cv_{cv_number}\")\n",
    "            yaml_path = Path(f\"../data/LNPDB_for_AGILE/AGILE/finetune/agile_lnp_hela_cv_{cv_number}/checkpoints/config_finetune.yaml\")\n",
    "            # replace yaml value based on dataset_name\n",
    "            with open(yaml_path, \"r\") as f:\n",
    "                yaml_config = yaml.safe_load(f)\n",
    "            # Modify the parameter\n",
    "            yaml_config['task_name'] = dataset_name\n",
    "            # Write the updated data back to the file\n",
    "            with open(yaml_path, 'w') as file:\n",
    "                yaml.safe_dump(yaml_config, file, default_flow_style=False, sort_keys=False)\n",
    "            command = [\"python\", \"infer_vis_LNPDB.py\", str(model_path)]\n",
    "            result = subprocess.run(command, cwd=agile_dir, capture_output=True, text=True)\n",
    "            try:\n",
    "                import re\n",
    "                stderr_vals = [float(x) for x in re.findall(r\"[+-]?(?:\\d+\\.\\d*|\\.\\d+|\\d+)(?:[eE][+-]?\\d+)?\", result.stdout)]\n",
    "            except ValueError:\n",
    "                print(f\"Warning: could not convert stdout/stderr to float for {dataset_name} CV {cv_number}\")\n",
    "                continue\n",
    "\n",
    "            # uncomment to show the direct AGILE output and errors\n",
    "            # print(result.stdout)\n",
    "            # print(result.stderr)\n",
    "            \n",
    "            dataset_metrics[dataset_name][\"loss\"].append(stderr_vals[-3])\n",
    "            dataset_metrics[dataset_name][\"rmse\"].append(stderr_vals[-2])\n",
    "            dataset_metrics[dataset_name][\"corr\"].append(stderr_vals[-1])\n",
    "\n",
    "    print(\"\\n=== Averaged results across CV splits ===\")\n",
    "    for dataset_name, metrics in dataset_metrics.items():\n",
    "        loss_avg = sum(metrics[\"loss\"]) / len(metrics[\"loss\"]) if metrics[\"loss\"] else float(\"nan\")\n",
    "        rmse_avg = sum(metrics[\"rmse\"]) / len(metrics[\"rmse\"]) if metrics[\"rmse\"] else float(\"nan\")\n",
    "        corr_avg = sum(metrics[\"corr\"]) / len(metrics[\"corr\"]) if metrics[\"corr\"] else float(\"nan\")\n",
    "        print(f\"{dataset_name}: Average loss = {loss_avg:.4f}, Average RMSE = {rmse_avg:.4f}, Pearson Corr = {corr_avg:.4f}\")\n",
    "\n",
    "cross_evaluate()\n",
    "\n",
    "# model prediction and ranking is saved inside the model folder in ../AGILE/finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad3b23a-cbdf-4e38-a4b5-1e6c3e1587d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
